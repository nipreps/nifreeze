{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Positron emission tomography (PET) data realignment example\n",
    "\n",
    "This example shows how to estimate the head motion of a PET dataset using `NiFreeze`.\n",
    "\n",
    "The notebook uses the `sub-02` dataset that was generated synthetically from\n",
    "a real PET dataset by adding random motion. The dataset can be installed from\n",
    "[GIN G-node](https://gin.g-node.org/nipreps-data/tests-nifreeze):\n",
    "\n",
    "```\n",
    "$ datalad install -g https://gin.g-node.org/nipreps-data/tests-nifreeze.git\n",
    "```\n",
    "\n",
    "after which the environment variable `TEST_DATA_HOME` will need to be set to\n",
    "point to the corresponding folder."
   ],
   "id": "6eecce4ffef2723"
  },
  {
   "cell_type": "code",
   "id": "4111cc1b-5123-407a-8ec6-56d65bc94bc4",
   "metadata": {},
   "source": [
    "from os import getenv\n",
    "from pathlib import Path\n",
    "\n",
    "from nifreeze.data.pet import from_nii\n",
    "\n",
    "# Install test data from gin.g-node.org:\n",
    "#   $ datalad install -g https://gin.g-node.org/nipreps-data/tests-nifreeze.git\n",
    "# and point the environment variable TEST_DATA_HOME to the corresponding folder\n",
    "DATA_PATH = Path(getenv(\"TEST_DATA_HOME\", str(Path.home() / \"nifreeze-tests\")))\n",
    "WORKDIR = Path.home() / \"tmp\" / \"nifreezedev\" / \"pet_data\"\n",
    "WORKDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "OUTPUT_DIR = WORKDIR / \"motion_estimation\"\n",
    "OUTPUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "pet_file = (\n",
    "    DATA_PATH / \"pet_data\" / \"sub-02\" / \"ses-baseline\" / \"pet\" / \"sub-02_ses-baseline_pet.nii.gz\"\n",
    ")\n",
    "json_file = (\n",
    "    DATA_PATH / \"pet_data\" / \"sub-02\" / \"ses-baseline\" / \"pet\" / \"sub-02_ses-baseline_pet.json\"\n",
    ")\n",
    "\n",
    "pet_dataset = from_nii(pet_file, temporal_file=json_file)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's first preprocess the data: we will smooth and threshold them.",
   "id": "a16bf55bda46c8c6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import nibabel as nb\n",
    "import numpy as np\n",
    "from nibabel.processing import smooth_image\n",
    "\n",
    "smooth_fwhm = 10.0\n",
    "thresh_pct = 20.0\n",
    "\n",
    "pet_img = nb.load(pet_file)\n",
    "pet_dataobj = pet_img.get_fdata()\n",
    "\n",
    "smoothed_img = smooth_image(nb.Nifti1Image(pet_dataobj, pet_img.affine), smooth_fwhm)\n",
    "thresh_val = np.percentile(smoothed_img.get_fdata(), thresh_pct)\n",
    "pet_dataobj[pet_dataobj < thresh_val] = 0\n",
    "\n",
    "preproc_pet_img_file = WORKDIR / \"sub-02_ses-baseline_pet_desc-preproc.nii.gz\"\n",
    "\n",
    "nb.save(nb.Nifti1Image(pet_dataobj, pet_img.affine), preproc_pet_img_file)"
   ],
   "id": "f3542f45e9b4178e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We will now create the PET dataset object.",
   "id": "34d7b1619d2a2f6d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pet_dataset = from_nii(preproc_pet_img_file, temporal_file=json_file)\n",
    "\n",
    "pet_dataset"
   ],
   "id": "3cb5a041-8947-4878-9086-9f056f1cc17a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Model fitting and motion correction\n",
    "\n",
    "The `nifreeze.model.BSplinePETModel` is a predictive model that employs\n",
    "a B-Spline-based interpolation method to model temporal signal evolution\n",
    "across PET frames. We will demonstrate how to estimate a held-out volume\n",
    "employing this model."
   ],
   "id": "48b9abd0d603385e"
  },
  {
   "cell_type": "code",
   "id": "81c8d5d5-a2c6-44fa-b9d4-4f21f809c6e1",
   "metadata": {},
   "source": [
    "from nifreeze.model import BSplinePETModel\n",
    "\n",
    "n_ctrl = 3\n",
    "order = 3\n",
    "\n",
    "# Create model with the reduced dataset\n",
    "model = BSplinePETModel(dataset=pet_dataset, n_ctrl=n_ctrl, order=order)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Let's now ask the model for a prediction at the time point pointed by the\n",
    "index value `2`. By calling `model.fit_predict` the model is fit on the\n",
    "remaining frames, and a prediction is requested on the time indicated by\n",
    "the provided index."
   ],
   "id": "d1184a969ab147a5"
  },
  {
   "cell_type": "code",
   "id": "dee05183-57b5-46ed-811a-c0b26a53a386",
   "metadata": {},
   "source": [
    "index = 2\n",
    "predicted = model.fit_predict(index=index)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We now save the uncorrected and corrected data so that we can visualize the\n",
    "difference."
   ],
   "id": "35dee72973730adf"
  },
  {
   "cell_type": "code",
   "id": "80b57514-d2a7-43bc-82e5-b4270822d4c5",
   "metadata": {},
   "source": [
    "import nibabel as nb\n",
    "\n",
    "# before\n",
    "nifti_img_before = nb.Nifti1Image(pet_dataset[index][0], pet_dataset.affine)\n",
    "output_path_before = \"before_mc.nii\"\n",
    "nifti_img_before.to_filename(output_path_before)\n",
    "\n",
    "# after\n",
    "nifti_img_after = nb.Nifti1Image(predicted, pet_dataset.affine)\n",
    "output_path_after = \"after_mc.nii\"\n",
    "nifti_img_after.to_filename(output_path_after)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Let's now visualize a number of axial, sagittal and coronal slices of the\n",
    "uncorrected and corrected data."
   ],
   "id": "5b3165b3641f754c"
  },
  {
   "cell_type": "code",
   "id": "452749dc-f7f1-4e6d-b4d6-49e67e742033",
   "metadata": {},
   "source": [
    "from niworkflows.viz.notebook import display\n",
    "\n",
    "moving_image = output_path_after\n",
    "fixed_image = output_path_before\n",
    "obj = display(\n",
    "    fixed_image,\n",
    "    moving_image,\n",
    "    fixed_label=\"PET_before\",\n",
    "    moving_label=\"PET_after\",\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Motion estimation\n",
    "\n",
    "We now want to have an estimate of the motion that the model corrects. We will\n",
    "need to instantiate the `nifreeze.estimator.PETMotionEstimator`, which will\n",
    "take an instance of the model. We will call `run` to get the parameters of the\n",
    "affine transform estimation. As the estimator runs, a registration process\n",
    "estimates the transform parameters between the held-out volume and the\n",
    "estimated volume: for each held-out volume index, the transform parameters are\n",
    "saved to the dataset."
   ],
   "id": "8973abb4db89247b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from nifreeze.estimator import Estimator\n",
    "\n",
    "strategy = \"linear\"\n",
    "estimator = Estimator(model=model, strategy=strategy)\n",
    "\n",
    "# Run the estimator\n",
    "estimator.run(pet_dataset, omp_nthreads=4)\n",
    "\n",
    "# Get the estimated motion affines\n",
    "affines = pet_dataset.motion_affines"
   ],
   "id": "d585e0e82d48ad81"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Let's now visualize the estimated motion: we will plot the translation and\n",
    "rotation components in the affine transform for each axis."
   ],
   "id": "f77c51d0aca62812"
  },
  {
   "cell_type": "code",
   "id": "d3627d44376b27f4",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nifreeze.registration.utils import compute_fd_from_motion, extract_motion_parameters\n",
    "\n",
    "# Assume `affines` is the list of affine matrices computed earlier\n",
    "motion_parameters = []\n",
    "\n",
    "for _idx, affine in enumerate(affines):\n",
    "    tx, ty, tz, rx, ry, rz = extract_motion_parameters(affine)\n",
    "    motion_parameters.append([tx, ty, tz, rx, ry, rz])\n",
    "\n",
    "motion_parameters = np.array(motion_parameters)\n",
    "estimated_fd = compute_fd_from_motion(motion_parameters)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4f141ebdb1643673",
   "metadata": {},
   "source": [
    "# Set up the matplotlib figure\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from nifreeze.viz.motion_viz import plot_volumewise_motion\n",
    "\n",
    "plot_volumewise_motion(np.arange(len(estimated_fd)), motion_parameters)\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e3f45164598d16f0",
   "metadata": {},
   "source": "For the dataset used in this example, we have access to the ground truth motion parameters that were used to corrupt the motion-free dataset. Let's now plot the ground truth motion to enable a visual comparison with the estimated motion."
  },
  {
   "cell_type": "code",
   "id": "1009ea77e1bdd0ee",
   "metadata": {},
   "source": [
    "from nifreeze.viz.motion_viz import plot_volumewise_motion\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "motion_gt_fname = (\n",
    "    DATA_PATH\n",
    "    / \"pet_data\"\n",
    "    / \"sub-02\"\n",
    "    / \"ses-baseline\"\n",
    "    / \"pet\"\n",
    "    / \"sub-02_ses-baseline_ground_truth_motion.csv\"\n",
    ")\n",
    "motion_gt_df = pd.read_csv(motion_gt_fname)\n",
    "\n",
    "frames = motion_gt_df[\"frame\"].to_numpy()\n",
    "\n",
    "# Construct motion_params array with shape (n_frames, 6): [trans_x, trans_y, trans_z, rot_x, rot_y, rot_z]\n",
    "motion_cols = [\"trans_x\", \"trans_y\", \"trans_z\", \"rot_x\", \"rot_y\", \"rot_z\"]\n",
    "motion_params = motion_gt_df[motion_cols].to_numpy()\n",
    "\n",
    "plot_volumewise_motion(frames, motion_params)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "113b4b4d1361b5ec",
   "metadata": {},
   "source": "Let's plot the estimated and the ground truth framewise displacement."
  },
  {
   "cell_type": "code",
   "id": "42ad9f87-3147-41bb-b04b-ba90325b811a",
   "metadata": {},
   "source": [
    "from nifreeze.viz.motion_viz import plot_framewise_displacement\n",
    "\n",
    "fd = pd.DataFrame({\"estimated\": estimated_fd, \"gt\": motion_gt_df[\"framewise_displacement\"].values})\n",
    "plot_framewise_displacement(fd, labels=[\"Estimated\", \"Ground truth\"])\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "14308ff4-d5b1-4270-aca2-0d7e9ccef27f",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
